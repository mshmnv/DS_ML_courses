{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия\n",
    "\n",
    "• работать с логистической регрессией\n",
    "• реализовывать градиентный спуск для ее настройки\n",
    "• использовать регуляризацию\n",
    "\n",
    "- Загрузите данные из файла data-logistic.csv. Это двумерная выборка, целевая переменная на которой принимает значения -1 или 1.\n",
    "- Убедитесь, что выше выписаны правильные формулы для градиентного спуска. Обратите внимание, что мы используем полноценный градиентный спуск, а не его стохастический вариант!\n",
    "- Реализуйте градиентный спуск для обычной и L2-регуляризованной (с коэффициентом регуляризации 10) логистической регрессии. Используйте длину шага k=0.1. В качестве начального приближения используйте вектор (0, 0).\n",
    "- Запустите градиентный спуск и доведите до сходимости (евклидово расстояние между векторами весов на соседних итерациях должно быть не больше 1e-5). Рекомендуется ограничить сверху число итераций десятью тысячами.\n",
    "- Какое значение принимает AUC-ROC на обучении без регуляризации и при ее использовании? Эти величины будут ответом на задание. В качестве ответа приведите два числа через пробел. Обратите внимание, что на вход функции roc_auc_score нужно подавать оценки вероятностей, подсчитанные обученным алгоритмом. Для этого воспользуйтесь сигмоидной функцией: a(x) = 1 / (1 + exp(-w1 x1 - w2 x2)). \n",
    "- Попробуйте поменять длину шага. Будет ли сходиться алгоритм, если делать более длинные шаги? Как меняется число итераций при уменьшении длины шага?\n",
    "- Попробуйте менять начальное приближение. Влияет ли оно на что-нибудь?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для настройки логистической регрессии нужно решить следующую задачу:\n",
    "![log_regression](./img/log_regression.png)\n",
    "\n",
    "*xi1 и xi2 — значение первого и второго признаков на объекте xi*\n",
    "\n",
    "\n",
    "Градиентный шаг для весов будет заключаться в одновременном обновлении весов w1 и w2 по следующим формулам :\n",
    "![log_regression](./img/log_regr_weights.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ROC AUC используется для алгоритмов бинарной классификации, выдающих оценку принадлежности объекта к одному из классов\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data-logistic.csv', header=None)\n",
    "X = data.values[:, 1:]\n",
    "y = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a1, b1, a2, b2):\n",
    "    return np.sqrt(np.square(a1 - a2) + np.square(b1 - b2))\n",
    "\n",
    "\n",
    "def a(w1, w2, x1, x2):\n",
    "    return 1. / (1 + np.exp(-w1*x1 - w2*x2))\n",
    "\n",
    "\n",
    "def logistic_regression(X, y, k, w, C, epsilon, max_iter):\n",
    "    \"\"\"\n",
    "    Logistic Regression classifier.\n",
    "\n",
    "    Parameters:\n",
    "    __________\n",
    "    k:\n",
    "        step length\n",
    "    w:\n",
    "        начальное приближение вектор (0,0)\n",
    "    C:\n",
    "        Inverse of regularization strength; must be a positive float.\n",
    "        Like in support vector machines, smaller values specify stronger regularization.\n",
    "    max_iter:\n",
    "        Maximum number of iterations taken for the solvers to converge.\n",
    "    \"\"\"\n",
    "    w1,w2 = w\n",
    "    for i in range(max_iter):\n",
    "        w1new = w1 + k * np.mean(y * X[:,0] * (1 - 1./(1 + np.exp(-y * (w1*X[:,0] + w2*X[:,1]))))) - k * C *w1\n",
    "        w2new = w2 + k * np.mean(y * X[:,1] * (1 - 1./(1 + np.exp(-y * (w1*X[:,0] + w2*X[:,1]))))) - k * C *w2\n",
    "        if distance(w1new, w2new, w1, w2) < epsilon:\n",
    "            break\n",
    "        w1, w2 = w1new, w2new\n",
    "\n",
    "    prediction = []\n",
    "    for i in range(len(X)):\n",
    "        prediction.append(a(w1, w2, X[i,0], X[i,1]))\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9267619047619047\n",
      "0.9362857142857142\n"
     ]
    }
   ],
   "source": [
    "# обычная логистическая регрессия\n",
    "p1 = logistic_regression(X, y, 0.1, [0.0, 0.0], 0, 0.000001, 100000)\n",
    "\n",
    "# L2-регуляризованная (с коэффициентом регуляризации C=10) логистическая регрессия\n",
    "p2 = logistic_regression(X, y, 0.1, [0.0, 0.0], 10, 0.000001, 100000)\n",
    "\n",
    "score1 = roc_auc_score(y, p1)\n",
    "score2 = roc_auc_score(y, p2)\n",
    "\n",
    "print(score1)\n",
    "print(score2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
