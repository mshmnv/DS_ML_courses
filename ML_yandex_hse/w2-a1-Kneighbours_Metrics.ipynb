{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор числа соседей\n",
    "\n",
    "- *В этом задании вам нужно подобрать оптимальное значение k для алгоритма kNN. Будем использовать набор данных Wine, где требуется предсказать сорт винограда, из которого изготовлено вино, используя результаты химических анализов.*\n",
    "1. Загрузите выборку Wine по адресу https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
    "2. Извлеките из данных признаки и классы. Класс записан в первом столбце (три варианта), признаки — в столбцах со второго по последний. Более подробно о сути признаков можно прочитать по адресу https://archive.ics.uci.edu/ml/datasets/Wine (см. также файл wine.names, приложенный к заданию)\n",
    "3. Оценку качества необходимо провести методом кроссвалидации по 5 блокам (5-fold). Создайте генератор разбиений, который перемешивает выборку перед формированием блоков (shuffle=True). Для воспроизводимости результата, создавайте генератор KFold с фиксированным параметром random_state=42. В качестве меры качества используйте долю верных ответов (accuracy).\n",
    "4. Найдите точность классификации на кросс-валидации для метода k ближайших соседей (sklearn.neighbors.KNeighborsClassifier), при k от 1 до 50. При каком k получилось оптимальное качество? Чему оно равно (число в интервале от 0 до 1)? Данные результаты и будут ответами на вопросы 1 и 2.\n",
    "5. Произведите масштабирование признаков с помощью функции sklearn.preprocessing.scale. Снова найдите оптимальное k на кроссвалидации.\n",
    "6. Какое значение k получилось оптимальным после приведения признаков к одному масштабу? Как изменилось значение качества? Приведите ответы на вопросы 3 и 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score  # вычислить качество на всех k разбиениях \n",
    "\n",
    "# нормирование признаков:\n",
    "# на входе: матрицу признаков\n",
    "# на выходе: масштабированная матрица, в которой каждый столбец имеет нулевое среднее значение и единичное стандартное отклонение\n",
    "from sklearn.preprocessing import scale              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без нормирования признаков:\n",
      "1 neighbors with accuracy 0.7304761904761905\n",
      "\n",
      "После нормирования признаков:\n",
      "29 neighbors with accuracy 0.9776190476190475\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('data/wine.data', delimiter=',')\n",
    "y = np.array(data[:,0], dtype=int)\n",
    "X = np.array(data[:, 1:])\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print('Без нормирования признаков:')\n",
    "k_neigh = 0\n",
    "max_score = 0\n",
    "for k in range(1, 51):\n",
    "    k_neighbors_model = KNeighborsClassifier(n_neighbors=k);\n",
    "    scores = cross_val_score(k_neighbors_model, X, y, cv=kf, scoring='accuracy')\n",
    "    if np.mean(scores) > max_score:\n",
    "        max_score = np.mean(scores)\n",
    "        k_neigh = k\n",
    "\n",
    "print(k_neigh, 'neighbors with accuracy', max_score)\n",
    "print()\n",
    "\n",
    "print('После нормирования признаков:')\n",
    "\n",
    "X = scale(X, axis=0, with_mean=True, with_std=True)\n",
    "\n",
    "k_neigh = 0\n",
    "max_score = 0\n",
    "for k in range(1, 51):\n",
    "    k_neighbors_model = KNeighborsClassifier(n_neighbors=k);\n",
    "    scores = cross_val_score(k_neighbors_model, X, y, cv=kf, scoring='accuracy')\n",
    "    if np.mean(scores) > max_score:\n",
    "        max_score = np.mean(scores)\n",
    "        k_neigh = k\n",
    "        \n",
    "print(k_neigh, 'neighbors with accuracy', max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор Метрики\n",
    "\n",
    "1. Загрузите выборку Boston с помощью функции sklearn.datasets.load_boston(). Результатом вызова данной функции является объект, у которого признаки записаны в поле data, а целевой вектор — в поле target.\n",
    "2. Приведите признаки в выборке к одному масштабу при помощи функции sklearn.preprocessing.scale.\n",
    "3. Переберите разные варианты параметра метрики p по сетке от 1 до 10 с таким шагом, чтобы всего было протестировано 200 вариантов (используйте функцию numpy.linspace). Используйте KNeighborsRegressor с n_neighbors=5 и weights='distance' — данный параметр добавляет в алгоритм веса, зависящие от расстояния до ближайших соседей. В качестве метрики качества используйте среднеквадратичную ошибку (параметр scoring='mean_squared_error' у cross_val_score; при использовании библиотеки scikit-learn версии 0.18.1 и выше необходимо указывать scoring='neg_mean_squared_error').  Качество оценивайте, как и в предыдущем задании, с помощью кросс-валидации по 5 блокам с random_state = 42, не забудьте включить перемешивание выборки (shuffle=True).\n",
    "4. Определите, при каком p качество на кросс-валидации оказалось оптимальным. Обратите внимание, что cross_val_score возвращает массив показателей качества по блокам; необходимо максимизировать среднее этих показателей. Это значение параметра и будет ответом на задачу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 param with max accuracy -11.833733363248196\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_boston()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "X = scale(X, with_mean=True, with_std=True)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "param = 0\n",
    "max_score = None\n",
    "for p_value in np.linspace(1, 10, 200):\n",
    "    k_neighbors_model = KNeighborsRegressor(n_neighbors=5, weights='distance', metric='minkowski', p=p_value) # weights='' добавляет в алгоритм веса, зависящие от расстояния до ближайших соседей\n",
    "    scores = cross_val_score(k_neighbors_model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    if max_score == None or np.max(scores) > max_score:\n",
    "        max_score = np.max(scores)\n",
    "        param = p_value\n",
    "\n",
    "    \n",
    "print(param, 'param with max accuracy', max_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
